{
  "name": "Squeeze Deep Learning onto Your Phone",
  "tagline": "",
  "body": "We are going to implement memory and energy efficient deep neural networks on mobile devices. The basic idea is to accelerate prediction process on already-trained model on a mobile GPU such as Tegra K1/X1. \r\n\r\n### Background\r\nDeep learning is a promising and popular AI technology that may greatly change the future world. If we can run deep learning models efficiently on mobile devices, it makes normal people the able to use state-of-the-art AI technologies in daily lives. However, deep learning is both memory and computational complicated, how to run it efficiently on mobile devices is a challenging problem.\r\n\r\nRecent research about bitwise neural network [1][2] can result in 58x faster convolutional operations and 32x memory savings, and deep compression [3] reduces the storage and energy required to run inference on large networks. All these techniques make deep learning running on resource constrained mobile devices possible.\r\n\r\n### Challenges\r\n* Mobile device has constrained memory and storage, but nerual networks with decent accuracy can easily have tens of thousands parameters\r\n* Enegy consumption is critical for mobile devices, nerual network prediction is computationally complicated\r\n\r\n### Resources:\r\n* Tegra K1 Dev Kit\r\n\r\n### Goals\r\n* 75% goal\r\n\t* Import trained models from popular deep learning frameworks such as Caffe to mobile devices. We plan to fisrt import AlexNet.\r\n\t* Run neural network prediction on Tegra K1 (GPU and CPU).\r\n* 100% goal\r\n\t* Achieve real time neural network prediction in on Tegra K1.\r\n\t* Evalute memory efficiency and energy efficiency, determine expensive part of the prediction process.\r\n\t* Reduce runtime memory footprint and enery footprint based on the evaluation results. Implementing deep compression and bitwise NN if needed.\r\n\t\r\n### Platform choice\r\nTegra K1 chip: this chip has a 192-core GPU and a quad-core ARM CPU, we can use this heterogeneity to evaluate deep learning runtime performance on different platforms. This chip is also targeting at mobile devices, for example the chip is small in size, and is very energy efficient. Besides, the GPU supports cuDNN, a cuda GPU deep learning framework that is widely used.\r\n\r\n### Schedule\r\n* 4/4 - 4/10 Set up the development environment. Read and undstand related papers.\r\n* 4/11- 4/16 Get a correct, unoptimized implementation. (75% goal)\r\n* 4/17 - 4/24 Implement deep compression to reduce the mode size.\r\n* 4/25 - 5/1 Implement XNOR-NET to accelarate prediction. (100% goal)\r\n* 5/2 - 5/8 Benchmark and Write up.\r\n\r\n### References\r\n[1] XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks\r\n\r\n[2] Bitwise Neural Networks\r\n\r\n[3] Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}